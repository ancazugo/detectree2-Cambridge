{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/PatBall1/detectree2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob, time, json, random, yaml\n",
    "from datetime import date, datetime\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectree2.preprocessing.tiling import tile_data_train, to_traintest_folders, tile_data\n",
    "from detectree2.models.predict import predict_on_data\n",
    "from detectree2.models.train import MyTrainer, setup_cfg, register_train_data, remove_registered_data, predictions_on_data, combine_dicts, get_tree_dicts, load_json_arr\n",
    "from detectree2.models.outputs import project_to_geojson, stitch_crowns, clean_crowns, to_eval_geojson, clean_predictions\n",
    "from detectree2.models.evaluation import site_f1_score2\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "\n",
    "import cv2\n",
    "import wandb\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "data_dir = os.getenv('DATA_FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectree_addons import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to COCO format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images in all folders need to be converted to the COCO format using detectree2 built-in methods. `preparare_tiled_data` and `to_traintest_folders` must be run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_path = data_dir + \"Cambridge/\"\n",
    "\n",
    "# Set tiling parameters\n",
    "buffer = 0\n",
    "tile_width = 200\n",
    "tile_height = 200\n",
    "threshold = 0\n",
    "tilename = 'city_center'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up input paths\n",
    "small_train_dir = site_path + \"train_small/\"\n",
    "small_crown_path = site_path + \"crowns/tiles_0.25m_160_20_0_train_crowns.shp\"\n",
    "small_rgb_path = site_path + \"rgb/\"\n",
    "small_data_name = 'Cambridge_25cm_2017_small'\n",
    "small_tiles_dir = site_path + \"tiles/\"\n",
    "small_train_dir = site_path + \"train/\"\n",
    "small_test_dir = site_path + \"test/\"\n",
    "\n",
    "small_imgs = read_multiple_rgb(small_rgb_path)\n",
    "\n",
    "# Read in crowns (then filter by an attribute if required)\n",
    "small_crowns = gpd.read_file(small_crown_path)\n",
    "small_crowns = small_crowns.to_crs(small_imgs[0].crs.data)\n",
    "\n",
    "# remove_registered_data(data_name)\n",
    "register_train_data(small_train_dir, small_data_name, val_fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_tiled_data_train(small_imgs, small_tiles_dir, tilename = tilename, buffer = buffer,\n",
    "                         tile_size = tile_width, crowns = small_crowns, threshold = threshold, dtype_bool = True)\n",
    "to_traintest_folders(small_tiles_dir, site_path, test_frac=0.1, folds=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up input paths\n",
    "large_train_dir = site_path + \"train_large/\"\n",
    "large_crown_path = site_path + \"crowns/tiles_0.25m_160_20_0_train_crowns.shp\"\n",
    "large_rgb_path = site_path + \"rgb/\"\n",
    "large_data_name = 'Cambridge_25cm_2017_large'\n",
    "large_tiles_dir = site_path + \"tiles/\"\n",
    "large_train_dir = site_path + \"train/\"\n",
    "large_test_dir = site_path + \"test/\"\n",
    "\n",
    "large_imgs = read_multiple_rgb(large_rgb_path)\n",
    "\n",
    "# Read in crowns (then filter by an attribute if required)\n",
    "large_crowns = gpd.read_file(large_crown_path)\n",
    "large_crowns = large_crowns.to_crs(large_imgs[0].crs.data)\n",
    "\n",
    "# remove_registered_data(data_name)\n",
    "register_train_data(large_train_dir, large_data_name, val_fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_tiled_data_train(large_imgs, large_tiles_dir, tilename = tilename, buffer = buffer,\n",
    "                         tile_size = tile_width, crowns = large_crowns, threshold = threshold, dtype_bool = True)\n",
    "to_traintest_folders(large_tiles_dir, site_path, test_frac=0.1, folds=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = site_path + \"test_large/\"\n",
    "test_crown_path = site_path + \"crowns/tiles_0.25m_160_20_0_test_crowns.shp\"\n",
    "test_rgb_path = site_path + \"rgb/\"\n",
    "test_tiles_dir = site_path + \"tiles/\"\n",
    "\n",
    "test_imgs = read_multiple_rgb(large_rgb_path)\n",
    "\n",
    "# Read in crowns (then filter by an attribute if required)\n",
    "test_crowns = gpd.read_file(test_crown_path)\n",
    "test_crowns = large_crowns.to_crs(test_imgs[0].crs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ONCE\n",
    "prepare_tiled_data_train(test_imgs, test_tiles_dir, tilename = tilename, buffer = buffer,\n",
    "                         tile_size = tile_width, crowns = test_crowns, threshold = threshold, dtype_bool = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training best models for each combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best runs\n",
    "params = {'half_dataset': {'coco': {'base_lr': 0.01341, 'gamma': 0.09478, 'warm_iter': 182, 'weight_decay': 0.0353, 'backbone_freeze': 3, 'batch_size_per_im': 1969, 'workers': 1},\n",
    "                           'paracou': {'base_lr': 0.01762, 'gamma': 0.1578, 'warm_iter': 160, 'weight_decay': 0.003313, 'backbone_freeze': 2, 'batch_size_per_im': 1707, 'workers': 1},\n",
    "                           'randresize': {'base_lr': 0.002454, 'gamma': 0.0581, 'warm_iter': 88, 'weight_decay': 0.09564, 'backbone_freeze': 2, 'batch_size_per_im': 650, 'workers': 2}},\n",
    "          'full_dataset': {'coco': {'base_lr': 0.005957, 'gamma': 0.2076, 'warm_iter': 166, 'weight_decay': 0.02602, 'backbone_freeze': 2, 'batch_size_per_im': 938, 'workers': 1}, \n",
    "                           'paracou': {'base_lr': 0.01709, 'gamma': 0.08866, 'warm_iter': 184, 'weight_decay': 0.006519, 'backbone_freeze': 2, 'batch_size_per_im': 623, 'workers': 6}, \n",
    "                           'randresize': {'base_lr': 0.01609, 'gamma': 0.1536, 'warm_iter': 194, 'weight_decay': 0.09707, 'backbone_freeze': 4, 'batch_size_per_im': 1172, 'workers': 4}}} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it is necessary to change the parameters for the different configurations, for the size of the training dataset and the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'half_dataset' # Select dataset\n",
    "model_name = 'randresize' # Select model\n",
    "data_name = large_data_name if dataset == 'full_dataset' else small_data_name # Trainning data name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base (pre-trained) model from the detectron2 model_zoo\n",
    "time_now = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "models = {'coco': \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\",\n",
    "          'paracou': data_dir + \"models/220723_withParacouUAV.pth\",\n",
    "          'randresize': data_dir + \"models/230103_randresize_full.pth\"}\n",
    "\n",
    "base_model = models[model_name]\n",
    "output_dir = data_dir + \"Cambridge/0.25m_160_20_0_models/\"\n",
    "train_out_dir = output_dir + f\"{time_now}_{model_name}/\"\n",
    "\n",
    "trains = (f\"{data_name}_train\",) # Registered train data\n",
    "tests = (f\"{data_name}_val\",) # Registered validation data\n",
    "\n",
    "if model_name == 'coco':\n",
    "    cfg = setup_cfg(base_model, trains, tests, eval_period=100,\n",
    "                    max_iter=3000, out_dir=train_out_dir,\n",
    "                    **params[dataset][model_name])\n",
    "    \n",
    "else:\n",
    "    cfg = setup_cfg(update_model=base_model, trains=trains, tests=tests,\n",
    "                    eval_period=100, max_iter=10000, out_dir=train_out_dir,\n",
    "                    **params[dataset][model_name])\n",
    "\n",
    "cfg_wandb = yaml.safe_load(cfg.dump())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will start a wandb run, assuming you have logged in with `wandb login` and have a project set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"detectree2-Cambridge\",\n",
    "    sync_tensorboard=True,\n",
    "    # track hyperparameters and run metadata\n",
    "    config = cfg_wandb\n",
    ")\n",
    "print(run.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is. the actual trainer, hence the longest cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(cfg, patience=5)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "run.log({'base_model': model_name, 'run_date': time_now})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is further setup for the location of the prediction files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = os.listdir(output_dir)\n",
    "model_name = trained_models[-1]\n",
    "# train_out_dir = output_dir + model_name + '/' #if os.path.exists(train_out_dir) == False or len(os.listdir()) == 0 else train_out_dir\n",
    "# experiment_metrics = load_json_arr(train_out_dir + 'metrics.json')\n",
    "\n",
    "saved_models = list(filter(lambda x: x[-4:] == '.pth', os.listdir(train_out_dir)))\n",
    "trained_model = train_out_dir + saved_models[-1]\n",
    "print(trained_model)\n",
    "train_pred_folder = train_out_dir + \"train/predictions/\"\n",
    "train_pred_geo_folder = train_out_dir + \"train/predictions_geo/\"\n",
    "test_pred_folder = train_out_dir + \"test/predictions/\"\n",
    "test_pred_geo_folder = train_out_dir + \"test/predictions_geo/\"\n",
    "\n",
    "# set up config\n",
    "cfg = setup_cfg(update_model=trained_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell produces the predictions for both the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_data(tiles_dir, DefaultPredictor(cfg), out_dir=train_pred_folder) # Train predictions (overfit)\n",
    "predict_on_data(test_tiles_dir, DefaultPredictor(cfg), out_dir=test_pred_folder) # Test prediction with change of folder\n",
    "\n",
    "# Read in the tiff file\n",
    "project_to_geojson(tiles_dir, train_pred_folder, train_pred_geo_folder)\n",
    "project_to_geojson(test_tiles_dir, test_pred_folder, test_pred_geo_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measures the model performance on the testing dataset and logs the results to wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prec, test_recall, test_f1 = site_f1_score2(\n",
    "    test_tiles_dir, test_directory=test_site_path + 'test',\n",
    "    pred_directory = test_pred_geo_folder[:-1],\n",
    "    IoU_threshold=0.5, border_filter=[False, 1], conf_threshold=0.6,\n",
    "    area_threshold=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({'Precision_test': test_prec, 'Recall_test': test_recall, 'F1_test': test_f1})\n",
    "run.finish()\n",
    "os.rename(train_out_dir, output_dir + f\"{run.name}/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
